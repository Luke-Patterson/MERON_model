{
    "accuracy": 0.542608695652174,
    "f1_score": 0.25071225071225073,
    "confusion_matrix": [
        [
            268,
            202
        ],
        [
            61,
            44
        ]
    ],
    "training_history": [
        {
            "epoch": 1,
            "train_loss": 5.336364943405678,
            "train_acc": 38.3025027203482,
            "train_f1": 0.4435721295387635,
            "val_loss": 2.0593615531921388,
            "val_acc": 81.73913043478261,
            "val_f1": 0.0,
            "learning_rate": 5e-06
        },
        {
            "epoch": 2,
            "train_loss": 5.288403363063417,
            "train_acc": 38.08487486398259,
            "train_f1": 0.4627006610009443,
            "val_loss": 2.0242564837137857,
            "val_acc": 81.73913043478261,
            "val_f1": 0.0,
            "learning_rate": 5e-06
        },
        {
            "epoch": 3,
            "train_loss": 4.937999955539046,
            "train_acc": 45.103373231773666,
            "train_f1": 0.5242809995285242,
            "val_loss": 1.99801553885142,
            "val_acc": 81.73913043478261,
            "val_f1": 0.0,
            "learning_rate": 5e-06
        },
        {
            "epoch": 4,
            "train_loss": 5.012521365593219,
            "train_acc": 43.68879216539717,
            "train_f1": 0.5219399538106235,
            "val_loss": 1.9960093339284262,
            "val_acc": 81.73913043478261,
            "val_f1": 0.0,
            "learning_rate": 5e-06
        },
        {
            "epoch": 5,
            "train_loss": 4.876818204748219,
            "train_acc": 45.37540805223068,
            "train_f1": 0.5440508628519528,
            "val_loss": 1.9987602313359578,
            "val_acc": 81.73913043478261,
            "val_f1": 0.0,
            "learning_rate": 5e-06
        },
        {
            "epoch": 6,
            "train_loss": 4.838642535538509,
            "train_acc": 42.16539717083787,
            "train_f1": 0.5143901324805847,
            "val_loss": 1.9775855143864949,
            "val_acc": 81.73913043478261,
            "val_f1": 0.0,
            "learning_rate": 5e-06
        },
        {
            "epoch": 7,
            "train_loss": 4.775328619726773,
            "train_acc": 44.50489662676823,
            "train_f1": 0.5506607929515418,
            "val_loss": 1.9585393031438192,
            "val_acc": 81.73913043478261,
            "val_f1": 0.0,
            "learning_rate": 5e-06
        },
        {
            "epoch": 8,
            "train_loss": 4.678087008410487,
            "train_acc": 49.727965179542984,
            "train_f1": 0.6047904191616766,
            "val_loss": 1.964974546432495,
            "val_acc": 81.73913043478261,
            "val_f1": 0.0,
            "learning_rate": 5e-06
        },
        {
            "epoch": 9,
            "train_loss": 4.546423340665883,
            "train_acc": 50.21762785636562,
            "train_f1": 0.6160302140159463,
            "val_loss": 1.9634679476420085,
            "val_acc": 81.73913043478261,
            "val_f1": 0.0,
            "learning_rate": 5e-06
        },
        {
            "epoch": 10,
            "train_loss": 4.491297310796277,
            "train_acc": 50.21762785636562,
            "train_f1": 0.6263781135157207,
            "val_loss": 1.9498125553131103,
            "val_acc": 81.73913043478261,
            "val_f1": 0.0,
            "learning_rate": 5e-06
        },
        {
            "epoch": 11,
            "train_loss": 4.3983851753432175,
            "train_acc": 53.15560391730141,
            "train_f1": 0.6504263093788063,
            "val_loss": 1.9487469991048176,
            "val_acc": 81.73913043478261,
            "val_f1": 0.0,
            "learning_rate": 5e-06
        },
        {
            "epoch": 12,
            "train_loss": 4.346221693630876,
            "train_acc": 54.13492927094668,
            "train_f1": 0.6623948738486184,
            "val_loss": 1.934689998626709,
            "val_acc": 81.73913043478261,
            "val_f1": 0.0,
            "learning_rate": 5e-06
        },
        {
            "epoch": 13,
            "train_loss": 4.1332985162734985,
            "train_acc": 55.60391730141458,
            "train_f1": 0.6720257234726688,
            "val_loss": 1.9321518898010255,
            "val_acc": 81.73913043478261,
            "val_f1": 0.0,
            "learning_rate": 5e-06
        },
        {
            "epoch": 14,
            "train_loss": 4.203367779994833,
            "train_acc": 54.62459194776932,
            "train_f1": 0.6695721077654516,
            "val_loss": 1.9264296054840089,
            "val_acc": 81.73913043478261,
            "val_f1": 0.0,
            "learning_rate": 5e-06
        },
        {
            "epoch": 15,
            "train_loss": 4.1088134708075685,
            "train_acc": 57.94341675734494,
            "train_f1": 0.7048491790759832,
            "val_loss": 1.9315622170766196,
            "val_acc": 81.73913043478261,
            "val_f1": 0.0,
            "learning_rate": 5e-06
        },
        {
            "epoch": 16,
            "train_loss": 4.068528639859166,
            "train_acc": 59.140369967355824,
            "train_f1": 0.7179872324446114,
            "val_loss": 1.9281262238820394,
            "val_acc": 81.73913043478261,
            "val_f1": 0.0,
            "learning_rate": 5e-06
        },
        {
            "epoch": 17,
            "train_loss": 3.9764283114466172,
            "train_acc": 59.24918389553863,
            "train_f1": 0.7174651075066013,
            "val_loss": 1.8939295689264932,
            "val_acc": 81.95652173913044,
            "val_f1": 0.023529411764705882,
            "learning_rate": 5e-06
        },
        {
            "epoch": 18,
            "train_loss": 3.9382963016115387,
            "train_acc": 59.466811751904245,
            "train_f1": 0.7221186124580381,
            "val_loss": 1.912675666809082,
            "val_acc": 81.73913043478261,
            "val_f1": 0.0,
            "learning_rate": 5e-06
        },
        {
            "epoch": 19,
            "train_loss": 3.879252084370317,
            "train_acc": 60.99020674646355,
            "train_f1": 0.7391778828664969,
            "val_loss": 1.8955094734827678,
            "val_acc": 81.30434782608695,
            "val_f1": 0.022727272727272728,
            "learning_rate": 5e-06
        },
        {
            "epoch": 20,
            "train_loss": 3.7433791818289923,
            "train_acc": 63.003264417845486,
            "train_f1": 0.7550432276657061,
            "val_loss": 1.903199815750122,
            "val_acc": 81.73913043478261,
            "val_f1": 0.0,
            "learning_rate": 5e-06
        },
        {
            "epoch": 21,
            "train_loss": 3.604265229455356,
            "train_acc": 63.003264417845486,
            "train_f1": 0.7559224694903087,
            "val_loss": 1.8829848766326904,
            "val_acc": 81.52173913043478,
            "val_f1": 0.06593406593406594,
            "learning_rate": 5e-06
        },
        {
            "epoch": 22,
            "train_loss": 3.611277596703891,
            "train_acc": 64.96191512513602,
            "train_f1": 0.7683453237410072,
            "val_loss": 1.8988327423731486,
            "val_acc": 81.73913043478261,
            "val_f1": 0.023255813953488372,
            "learning_rate": 5e-06
        },
        {
            "epoch": 23,
            "train_loss": 3.621362094221444,
            "train_acc": 65.28835690968444,
            "train_f1": 0.778318276580959,
            "val_loss": 1.8851230303446451,
            "val_acc": 81.30434782608695,
            "val_f1": 0.06521739130434782,
            "learning_rate": 5e-06
        },
        {
            "epoch": 24,
            "train_loss": 3.5073890439395248,
            "train_acc": 68.00870511425462,
            "train_f1": 0.7962577962577962,
            "val_loss": 1.8804767767588297,
            "val_acc": 81.95652173913044,
            "val_f1": 0.04597701149425287,
            "learning_rate": 5e-06
        },
        {
            "epoch": 25,
            "train_loss": 3.4536529779434204,
            "train_acc": 69.26006528835691,
            "train_f1": 0.8051052086926527,
            "val_loss": 1.8752360105514527,
            "val_acc": 81.30434782608695,
            "val_f1": 0.0851063829787234,
            "learning_rate": 5e-06
        },
        {
            "epoch": 26,
            "train_loss": 3.410399350626715,
            "train_acc": 68.44396082698586,
            "train_f1": 0.8036560595802302,
            "val_loss": 1.8677400588989257,
            "val_acc": 81.30434782608695,
            "val_f1": 0.10416666666666667,
            "learning_rate": 5e-06
        },
        {
            "epoch": 27,
            "train_loss": 3.345473392256375,
            "train_acc": 66.97497279651796,
            "train_f1": 0.794167514411665,
            "val_loss": 1.8564578771591187,
            "val_acc": 80.0,
            "val_f1": 0.1320754716981132,
            "learning_rate": 5e-06
        },
        {
            "epoch": 28,
            "train_loss": 3.3733596555117904,
            "train_acc": 69.1512513601741,
            "train_f1": 0.8097953706809795,
            "val_loss": 1.8622079292933147,
            "val_acc": 80.43478260869566,
            "val_f1": 0.1509433962264151,
            "learning_rate": 5e-06
        },
        {
            "epoch": 29,
            "train_loss": 3.290490454640882,
            "train_acc": 71.54515778019586,
            "train_f1": 0.8267638290824777,
            "val_loss": 1.8637933095296224,
            "val_acc": 80.43478260869566,
            "val_f1": 0.11764705882352941,
            "learning_rate": 5e-06
        },
        {
            "epoch": 30,
            "train_loss": 3.261113561432937,
            "train_acc": 72.25244831338411,
            "train_f1": 0.8331151832460733,
            "val_loss": 1.8581066687901815,
            "val_acc": 80.0,
            "val_f1": 0.11538461538461539,
            "learning_rate": 5e-06
        },
        {
            "epoch": 31,
            "train_loss": 3.1788420800505013,
            "train_acc": 71.05549510337323,
            "train_f1": 0.8241903502974224,
            "val_loss": 1.8403891642888388,
            "val_acc": 78.26086956521739,
            "val_f1": 0.15254237288135594,
            "learning_rate": 5e-06
        },
        {
            "epoch": 32,
            "train_loss": 3.1162085944208604,
            "train_acc": 72.0348204570185,
            "train_f1": 0.8314754098360656,
            "val_loss": 1.8431820313135783,
            "val_acc": 78.04347826086956,
            "val_f1": 0.17886178861788618,
            "learning_rate": 5e-06
        },
        {
            "epoch": 33,
            "train_loss": 2.982766369293476,
            "train_acc": 71.87159956474429,
            "train_f1": 0.8315412186379928,
            "val_loss": 1.8453904151916505,
            "val_acc": 77.17391304347827,
            "val_f1": 0.1732283464566929,
            "learning_rate": 5e-06
        },
        {
            "epoch": 34,
            "train_loss": 3.020393700435244,
            "train_acc": 71.38193688792165,
            "train_f1": 0.8289986996098829,
            "val_loss": 1.8464955806732177,
            "val_acc": 75.0,
            "val_f1": 0.20689655172413793,
            "learning_rate": 5e-06
        },
        {
            "epoch": 35,
            "train_loss": 2.9557483730645013,
            "train_acc": 72.79651795429815,
            "train_f1": 0.8374512353706112,
            "val_loss": 1.8330485741297404,
            "val_acc": 69.56521739130434,
            "val_f1": 0.21348314606741572,
            "learning_rate": 5e-06
        },
        {
            "epoch": 36,
            "train_loss": 2.983084464895314,
            "train_acc": 75.0816104461371,
            "train_f1": 0.8548795944233206,
            "val_loss": 1.8252219676971435,
            "val_acc": 65.21739130434783,
            "val_f1": 0.25925925925925924,
            "learning_rate": 5e-06
        },
        {
            "epoch": 37,
            "train_loss": 2.8941471371157417,
            "train_acc": 73.77584330794342,
            "train_f1": 0.8462029355456286,
            "val_loss": 1.8195741097132365,
            "val_acc": 59.78260869565217,
            "val_f1": 0.26294820717131473,
            "learning_rate": 5e-06
        },
        {
            "epoch": 38,
            "train_loss": 2.7916005808731605,
            "train_acc": 73.06855277475516,
            "train_f1": 0.8411934552454283,
            "val_loss": 1.8360081434249877,
            "val_acc": 64.78260869565217,
            "val_f1": 0.2831858407079646,
            "learning_rate": 5e-06
        },
        {
            "epoch": 39,
            "train_loss": 2.7912191563639146,
            "train_acc": 75.57127312295974,
            "train_f1": 0.8574150523975865,
            "val_loss": 1.8189286947250367,
            "val_acc": 53.91304347826087,
            "val_f1": 0.2638888888888889,
            "learning_rate": 5e-06
        },
        {
            "epoch": 40,
            "train_loss": 2.795575811945159,
            "train_acc": 75.1360174102285,
            "train_f1": 0.8559722659943272,
            "val_loss": 1.8265682379404704,
            "val_acc": 56.30434782608695,
            "val_f1": 0.2846975088967972,
            "learning_rate": 5e-06
        },
        {
            "epoch": 41,
            "train_loss": 2.7153409143974043,
            "train_acc": 75.51686615886834,
            "train_f1": 0.8587570621468926,
            "val_loss": 1.8120369036992392,
            "val_acc": 50.43478260869565,
            "val_f1": 0.2692307692307692,
            "learning_rate": 5e-06
        },
        {
            "epoch": 42,
            "train_loss": 2.6686946441387307,
            "train_acc": 74.9183895538629,
            "train_f1": 0.8551680804272699,
            "val_loss": 1.8135485808054606,
            "val_acc": 54.78260869565217,
            "val_f1": 0.2876712328767123,
            "learning_rate": 5e-06
        },
        {
            "epoch": 43,
            "train_loss": 2.6796446874223907,
            "train_acc": 77.14907508161045,
            "train_f1": 0.8699690402476781,
            "val_loss": 1.8117613792419434,
            "val_acc": 53.04347826086956,
            "val_f1": 0.2751677852348993,
            "learning_rate": 5e-06
        },
        {
            "epoch": 44,
            "train_loss": 2.620822002147806,
            "train_acc": 77.52992383025027,
            "train_f1": 0.8716195212931303,
            "val_loss": 1.807645567258199,
            "val_acc": 46.52173913043478,
            "val_f1": 0.2634730538922156,
            "learning_rate": 5e-06
        },
        {
            "epoch": 45,
            "train_loss": 2.4941422528234023,
            "train_acc": 77.80195865070729,
            "train_f1": 0.8727386150966937,
            "val_loss": 1.8142631928126016,
            "val_acc": 49.130434782608695,
            "val_f1": 0.2641509433962264,
            "learning_rate": 5e-06
        },
        {
            "epoch": 46,
            "train_loss": 2.577124696353386,
            "train_acc": 78.0195865070729,
            "train_f1": 0.8750773036487323,
            "val_loss": 1.7993703047434488,
            "val_acc": 40.0,
            "val_f1": 0.25806451612903225,
            "learning_rate": 5e-06
        },
        {
            "epoch": 47,
            "train_loss": 2.4997856329227317,
            "train_acc": 77.47551686615887,
            "train_f1": 0.8714285714285714,
            "val_loss": 1.7981782992680868,
            "val_acc": 39.78260869565217,
            "val_f1": 0.2691292875989446,
            "learning_rate": 5e-06
        },
        {
            "epoch": 48,
            "train_loss": 2.4480409745512337,
            "train_acc": 79.92383025027203,
            "train_f1": 0.8878760255241568,
            "val_loss": 1.788345177968343,
            "val_acc": 36.52173913043478,
            "val_f1": 0.25888324873096447,
            "learning_rate": 5e-06
        },
        {
            "epoch": 49,
            "train_loss": 2.415543695975994,
            "train_acc": 80.63112078346029,
            "train_f1": 0.8917933130699088,
            "val_loss": 1.7973918914794922,
            "val_acc": 40.869565217391305,
            "val_f1": 0.26881720430107525,
            "learning_rate": 5e-06
        },
        {
            "epoch": 50,
            "train_loss": 2.396665404582846,
            "train_acc": 78.78128400435256,
            "train_f1": 0.8808068459657702,
            "val_loss": 1.7881844600041708,
            "val_acc": 34.56521739130435,
            "val_f1": 0.26405867970660146,
            "learning_rate": 5e-06
        },
        {
            "epoch": 51,
            "train_loss": 2.358042231921492,
            "train_acc": 78.29162132752992,
            "train_f1": 0.8769657724329325,
            "val_loss": 1.7781551202138266,
            "val_acc": 32.17391304347826,
            "val_f1": 0.26066350710900477,
            "learning_rate": 5e-06
        },
        {
            "epoch": 52,
            "train_loss": 2.3353585950259506,
            "train_acc": 78.83569096844396,
            "train_f1": 0.88107612350963,
            "val_loss": 1.7930413722991942,
            "val_acc": 35.65217391304348,
            "val_f1": 0.263681592039801,
            "learning_rate": 5e-06
        },
        {
            "epoch": 53,
            "train_loss": 2.2964067808512985,
            "train_acc": 78.94450489662677,
            "train_f1": 0.88168755732192,
            "val_loss": 1.7902053276697794,
            "val_acc": 34.34782608695652,
            "val_f1": 0.27053140096618356,
            "learning_rate": 5e-06
        },
        {
            "epoch": 54,
            "train_loss": 2.2760362131842253,
            "train_acc": 79.16213275299238,
            "train_f1": 0.8829819737244119,
            "val_loss": 1.7778342008590697,
            "val_acc": 29.782608695652176,
            "val_f1": 0.2675736961451247,
            "learning_rate": 5e-06
        },
        {
            "epoch": 55,
            "train_loss": 2.1879857141396095,
            "train_acc": 78.99891186071817,
            "train_f1": 0.8822452715070165,
            "val_loss": 1.7856761693954468,
            "val_acc": 31.304347826086957,
            "val_f1": 0.2616822429906542,
            "learning_rate": 5e-06
        },
        {
            "epoch": 56,
            "train_loss": 2.169982036639904,
            "train_acc": 78.50924918389553,
            "train_f1": 0.8788715118061944,
            "val_loss": 1.7824702898661295,
            "val_acc": 30.652173913043477,
            "val_f1": 0.26666666666666666,
            "learning_rate": 5e-06
        },
        {
            "epoch": 57,
            "train_loss": 2.1989046437986968,
            "train_acc": 79.4341675734494,
            "train_f1": 0.8852459016393442,
            "val_loss": 1.774354839324951,
            "val_acc": 28.26086956521739,
            "val_f1": 0.26666666666666666,
            "learning_rate": 5e-06
        },
        {
            "epoch": 58,
            "train_loss": 2.1387591773066026,
            "train_acc": 79.05331882480958,
            "train_f1": 0.8826577263029565,
            "val_loss": 1.7753436803817748,
            "val_acc": 28.26086956521739,
            "val_f1": 0.26339285714285715,
            "learning_rate": 5e-06
        },
        {
            "epoch": 59,
            "train_loss": 2.112462623365994,
            "train_acc": 78.56365614798695,
            "train_f1": 0.8795843520782396,
            "val_loss": 1.7683494249979654,
            "val_acc": 26.08695652173913,
            "val_f1": 0.2608695652173913,
            "learning_rate": 5e-06
        },
        {
            "epoch": 60,
            "train_loss": 2.13512423942829,
            "train_acc": 78.07399347116431,
            "train_f1": 0.8762665029167946,
            "val_loss": 1.7759315967559814,
            "val_acc": 27.608695652173914,
            "val_f1": 0.2713347921225383,
            "learning_rate": 5e-06
        },
        {
            "epoch": 61,
            "train_loss": 2.081125522481984,
            "train_acc": 79.379760609358,
            "train_f1": 0.8849073792894018,
            "val_loss": 1.7776374816894531,
            "val_acc": 29.130434782608695,
            "val_f1": 0.26244343891402716,
            "learning_rate": 5e-06
        },
        {
            "epoch": 62,
            "train_loss": 2.069039990162027,
            "train_acc": 80.63112078346029,
            "train_f1": 0.8925769462884732,
            "val_loss": 1.7768539349238077,
            "val_acc": 25.652173913043477,
            "val_f1": 0.2565217391304348,
            "learning_rate": 5e-06
        }
    ]
}